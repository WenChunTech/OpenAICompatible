# OpenAICompatible

ä¸€ä¸ªæä¾›å¤šç§å¤§è¯­è¨€æ¨¡å‹æœåŠ¡æä¾›å•†æ¥å£çš„ä¸­é—´ä»¶ï¼Œæ”¯æŒåŠ¨æ€åˆ‡æ¢æœåŠ¡æä¾›å•†ï¼Œæä¾›OpenAIå…¼å®¹çš„APIæ¥å£ã€‚

## ç‰¹æ€§

- ğŸ”„ æ”¯æŒå¤šç§æœåŠ¡æä¾›å•†ï¼ˆCodeGeexã€Qwenã€Gemini CLIç­‰ï¼‰
- ğŸ¯ æä¾›å®Œå…¨OpenAIå…¼å®¹çš„APIæ¥å£
- ğŸ”Œ æ˜“äºæ‰©å±•æ–°çš„æœåŠ¡æä¾›å•†
- ğŸ› ï¸ æ”¯æŒè·¨å¹³å°ï¼ˆWindowsã€Linuxã€MacOSï¼‰
- ğŸš€ ç®€å•æ˜“ç”¨çš„é…ç½®
- ğŸ“Š æ”¯æŒå¤šå®ä¾‹é…ç½®å’Œè´Ÿè½½å‡è¡¡
- ğŸŒŠ æ”¯æŒæµå¼å“åº”ï¼ˆSSEï¼‰
- ğŸ›¡ï¸ å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶
- ğŸ”§ æ”¯æŒå¤šç§è®¤è¯æ–¹å¼

## æ¶æ„

```mermaid
graph LR
    Client[å®¢æˆ·ç«¯] --> |OpenAIå…¼å®¹è¯·æ±‚| Server[OpenAICompatibleæœåŠ¡]
    Server --> |è´Ÿè½½å‡è¡¡| LoadBalancer[è´Ÿè½½å‡è¡¡å™¨]
    LoadBalancer --> |æ ¹æ®é…ç½®è·¯ç”±| Provider1[CodeGeex Provider]
    LoadBalancer --> |æ ¹æ®é…ç½®è·¯ç”±| Provider2[Qwen Provider]
    LoadBalancer --> |æ ¹æ®é…ç½®è·¯ç”±| Provider3[Gemini CLI Provider]
    Provider1 --> |è½¬æ¢è¯·æ±‚| CodeGeex[CodeGeex API]
    Provider2 --> |è½¬æ¢è¯·æ±‚| Qwen[Qwen API]
    Provider3 --> |è½¬æ¢è¯·æ±‚| Gemini[Gemini CLI API]

    subgraph é…ç½®ç®¡ç†
        Config[é…ç½®æ–‡ä»¶] --> |é…ç½®åŠ è½½| Server
        Config --> |å¤šå®ä¾‹é…ç½®| LoadBalancer
    end

    subgraph é”™è¯¯å¤„ç†
        ErrorHandler[é”™è¯¯å¤„ç†å™¨] --> |ç»Ÿä¸€é”™è¯¯å¤„ç†| Server
    end

    subgraph æµå¼å“åº”
        StreamHandler[æµå¼å¤„ç†å™¨] --> |SSEå“åº”| Server
    end
```

## å®‰è£…

### é¢„ç¼–è¯‘äºŒè¿›åˆ¶

ä»[releases](https://github.com/WenChunTech/OpenAICompatible/releases)é¡µé¢ä¸‹è½½é€‚åˆä½ ç³»ç»Ÿçš„é¢„ç¼–è¯‘äºŒè¿›åˆ¶æ–‡ä»¶ã€‚

### ä½¿ç”¨Docker

```bash
docker pull ghcr.io/wenchuntech/openaicompatible:latest
docker run -d -v config.json:/app/config.json -p 8080:8080 openaicompatible:latest
```

### ä»æºç æ„å»º

éœ€æ±‚ï¼š
- Go 1.24.2 æˆ–æ›´é«˜ç‰ˆæœ¬

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/WenChunTech/OpenAICompatible.git
cd OpenAICompatible

# æ„å»º
./build.sh
```

## é…ç½®

åˆ›å»º`config.json`é…ç½®æ–‡ä»¶ï¼š

```json
{
    "host": "0.0.0.0",
    "port": 8080,
    "codegeex": [
        {
            "token": "ä½ çš„CodeGeex token 1",
            "prefix": "codegeex1",
            "user_id": "user_id_1",
            "user_role": 1,
            "ide": "vscode",
            "ide_version": "1.0.0",
            "plugin_version": "1.0.0",
            "machine_id": "machine_1",
            "talk_id": "talk_1",
            "locale": "zh-CN"
        },
        {
            "token": "ä½ çš„CodeGeex token 2",
            "prefix": "codegeex2"
        }
    ],
    "qwen": [
        {
            "token": "ä½ çš„Qwen token 1",
            "prefix": "qwen1"
        },
        {
            "token": "ä½ çš„Qwen token 2",
            "prefix": "qwen2"
        }
    ],
    "gemini_cli": [
        {
            "project_id": "ä½ çš„Geminié¡¹ç›®ID",
            "token": {
              // ä½ çš„Geminiè®¿é—®ä»¤ç‰Œ
              },
            "prefix": "gemini1"
        }
    ]
}
```

### é…ç½®é¡¹è¯´æ˜

- `host`: æœåŠ¡ç›‘å¬åœ°å€
- `port`: æœåŠ¡ç›‘å¬ç«¯å£
- `codegeex`: CodeGeexæœåŠ¡é…ç½®æ•°ç»„
  - `token`: è®¿é—®ä»¤ç‰Œ
  - `prefix`: å‰ç¼€æ ‡è¯†ï¼ˆå¯é€‰ï¼‰
  - `user_id`: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
  - `user_role`: ç”¨æˆ·è§’è‰²ï¼ˆå¯é€‰ï¼‰
  - `ide`: IDEæ ‡è¯†ï¼ˆå¯é€‰ï¼‰
  - `ide_version`: IDEç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
  - `plugin_version`: æ’ä»¶ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
  - `machine_id`: æœºå™¨IDï¼ˆå¯é€‰ï¼‰
  - `talk_id`: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
  - `locale`: è¯­è¨€ç¯å¢ƒï¼ˆå¯é€‰ï¼‰
- `qwen`: QwenæœåŠ¡é…ç½®æ•°ç»„
  - `token`: è®¿é—®ä»¤ç‰Œ
  - `prefix`: å‰ç¼€æ ‡è¯†ï¼ˆå¯é€‰ï¼‰
- `gemini_cli`: Gemini CLIæœåŠ¡é…ç½®æ•°ç»„
  - `project_id`: Google Cloudé¡¹ç›®ID
  - `token`: OAuth2è®¿é—®ä»¤ç‰Œ
  - `prefix`: å‰ç¼€æ ‡è¯†ï¼ˆå¯é€‰ï¼‰

### å¤šå®ä¾‹é…ç½®

ç³»ç»Ÿæ”¯æŒæ¯ä¸ªæœåŠ¡æä¾›å•†é…ç½®å¤šä¸ªå®ä¾‹ï¼Œä¼šè‡ªåŠ¨è¿›è¡Œè´Ÿè½½å‡è¡¡ã€‚è¯·æ±‚æ—¶ä¼šæŒ‰é¡ºåºè½®è¯¢ä½¿ç”¨ä¸åŒçš„å®ä¾‹ã€‚

### è®¤è¯æ–¹å¼

- CodeGeex: ä½¿ç”¨API Token
- Qwen: ä½¿ç”¨API Token
- Gemini CLI: ä½¿ç”¨OAuth2 Token

## æ”¯æŒçš„æ¨¡å‹

ç³»ç»Ÿä¼šè‡ªåŠ¨ä»å„ä¸ªæœåŠ¡æä¾›å•†è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ï¼Œå¹¶ä¸ºæ¯ä¸ªæ¨¡å‹æ·»åŠ å‰ç¼€ä»¥åŒºåˆ†æ¥æºã€‚ä¾‹å¦‚ï¼š

- `codegeex/codegeex4`: CodeGeex 4æ¨¡å‹
- `qwen/qwen-turbo`: Qwen Turboæ¨¡å‹
- `gemini_cli/gemini-pro`: Gemini Proæ¨¡å‹

å®Œæ•´çš„æ¨¡å‹åˆ—è¡¨å¯ä»¥é€šè¿‡`/v1/models` APIè·å–ã€‚

## APIä½¿ç”¨ç¤ºä¾‹

### èŠå¤©è¡¥å…¨API

```bash
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "user",
        "content": "ä½ å¥½"
      }
    ]
  }'
```

### è·å–æ¨¡å‹åˆ—è¡¨API

```bash
curl http://localhost:8080/v1/models
```

## æ‰©å±•æ–°çš„æœåŠ¡æä¾›å•†

1. åœ¨`src/provider`ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æœåŠ¡æä¾›å•†åŒ…
2. å®ç°`Provider`æ¥å£ï¼š
```go
type Provider interface {
    HandleChatCompleteRequest(ctx context.Context, r *model.OpenAIChatCompletionRequest) (*request.Response, error)
    HandleChatCompleteResponse(ctx context.Context, w http.ResponseWriter, r *request.Response) error
    HandleListModelRequest(ctx context.Context) (*request.Response, error)
    HandleListModelResponse(ctx context.Context, w http.ResponseWriter, r *request.Response) (*model.OpenAIModelListResponse,error)
}
```
3. åœ¨`config.json`ä¸­æ·»åŠ ç›¸åº”çš„é…ç½®é¡¹
4. åœ¨`main.go`ä¸­æ³¨å†Œæ–°çš„æœåŠ¡æä¾›å•†

### é”™è¯¯å¤„ç†

ç³»ç»Ÿæä¾›äº†ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼ŒåŒ…æ‹¬ï¼š

- è¯·æ±‚éªŒè¯é”™è¯¯
- æœåŠ¡æä¾›å•†è¿æ¥é”™è¯¯

### æµå¼å“åº”

ç³»ç»Ÿæ”¯æŒé€šè¿‡Server-Sent Events (SSE)å®ç°æµå¼å“åº”ï¼š

1. åœ¨è¯·æ±‚ä¸­è®¾ç½®`"stream": true`
2. ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†SSEæ ¼å¼çš„å“åº”
3. æ”¯æŒé”™è¯¯æµçš„å¤„ç†

æµå¼å“åº”ä½¿ç”¨ç¤ºä¾‹ï¼š
```bash
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "codegeex/codegeex4",
    "messages": [
      {
        "role": "user",
        "content": "ä½ å¥½"
      }
    ],
    "stream": true
  }'
```

## è´¡çŒ®æŒ‡å—

å¦‚æœæ‚¨æƒ³ä¸ºOpenAICompatibleé¡¹ç›®åšå‡ºè´¡çŒ®ï¼Œè¯·éµå¾ª[COMMIT_RULE.md](COMMIT_RULE.md)æ–‡ä»¶ä¸­çš„æäº¤è§„åˆ™ã€‚


## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶